Bootstrap: docker
From: nvidia/cuda:12.1.0-devel-ubuntu22.04

%files
    pyproject.toml /transcriptomic-fms/
    README.md /transcriptomic-fms/
    transcriptomic_fms /transcriptomic-fms/transcriptomic_fms

%post
    # Suppress debconf and update-alternatives warnings
    export DEBIAN_FRONTEND=noninteractive
    export UCF_FORCE_CONFFNEW=1
    
    # Set CUDA paths (base image has CUDA installed at /usr/local/cuda)
    export PATH="/usr/local/cuda/bin:$PATH"
    export LD_LIBRARY_PATH="/usr/local/cuda/lib64:$LD_LIBRARY_PATH"
    
    # Update package lists and install system dependencies
    # Base image already has CUDA toolkit (nvcc) installed
    apt-get update -qq
    apt-get install -y -qq --no-install-recommends \
        build-essential \
        git \
        curl \
        ca-certificates \
        python3.11 \
        python3.11-dev \
        python3-pip \
        python3-venv
    
    # Verify nvcc is available (should be in base CUDA image)
    if ! command -v nvcc &> /dev/null && [ ! -f /usr/local/cuda/bin/nvcc ]; then
        echo "ERROR: nvcc not found in CUDA base image!"
        echo "Checked: command -v nvcc and /usr/local/cuda/bin/nvcc"
        exit 1
    fi
    
    # Ensure nvcc is in PATH (may not be in default PATH during build)
    if [ -f /usr/local/cuda/bin/nvcc ] && ! command -v nvcc &> /dev/null; then
        export PATH="/usr/local/cuda/bin:$PATH"
    fi
    
    # Create symlink for python (base image may use python3)
    ln -sf /usr/bin/python3.11 /usr/bin/python || true
    ln -sf /usr/bin/python3.11 /usr/bin/python3 || true
    
    # Clean up apt lists to reduce image size
    rm -rf /var/lib/apt/lists/*

    # Install uv
    curl -LsSf https://astral.sh/uv/install.sh | sh
    export PATH="/root/.local/bin:/usr/local/cuda/bin:$PATH"

    # Set working directory
    cd /transcriptomic-fms

    # Install PyTorch with CUDA support first (before other dependencies)
    # This is needed for flash-attn and GPU-enabled models
    echo "Installing PyTorch with CUDA support..."
    if ! /root/.local/bin/uv pip install --system --index-url https://download.pytorch.org/whl/cu121 \
        "torch>=2.0.0,<2.3.0"; then
        echo "Warning: PyTorch installation failed."
    fi

    # Install flash-attn (REQUIRED - CUDA toolkit already installed above)
    echo "Installing flash-attn (this will take 30-60 minutes)..."
    
    NVCC_VERSION=$(nvcc --version 2>/dev/null | grep "release" | sed -n 's/.*release \([0-9.]*\).*/\1/p' | head -1 || echo "unknown")
    echo "nvcc found (CUDA $NVCC_VERSION)"
    
    if ! /root/.local/bin/uv pip install --system "flash-attn<1.0.5"; then
        echo "ERROR: flash-attn installation failed!"
        exit 1
    fi
    echo "flash-attn installed successfully"

    # Install the package and all dependencies from pyproject.toml (in editable mode)
    echo "Installing package and dependencies from pyproject.toml..."
    /root/.local/bin/uv pip install --system -e .

    # Ensure torch is still the CUDA version
    /root/.local/bin/uv pip install --system --index-url https://download.pytorch.org/whl/cu121 \
        --upgrade-package torch "torch>=2.0.0,<2.3.0" || true

    # Create data and output directories
    mkdir -p /transcriptomic-fms/data
    mkdir -p /transcriptomic-fms/output
    mkdir -p /transcriptomic-fms/models

%environment
    export PATH="/root/.local/bin:/usr/local/cuda/bin:$PATH"
    export LD_LIBRARY_PATH="/usr/local/cuda/lib64:$LD_LIBRARY_PATH"
    export PYTHONPATH="/transcriptomic-fms:$PYTHONPATH"
    export PYTHONUNBUFFERED=1

%runscript
    # Default command
    exec python -m transcriptomic_fms.cli.main "$@"

%labels
    Author "Ahmed Sallam"
    Version "0.1.0"
    Description "Transcriptomic Foundation Models - Embedding generation infrastructure"

