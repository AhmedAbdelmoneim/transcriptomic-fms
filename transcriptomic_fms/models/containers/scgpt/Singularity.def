Bootstrap: localimage
From: transcriptomic-fms.sif

%files
    # Files are copied from build context (project root)
    # This file should be built from the project root directory
    # Build with: apptainer build transcriptomic-fms-scgpt.sif transcriptomic_fms/models/containers/scgpt/Singularity.def
    # Note: Requires base container (transcriptomic-fms.sif) to be built first
    pyproject.toml /transcriptomic-fms/
    README.md /transcriptomic-fms/
    transcriptomic_fms /transcriptomic-fms/transcriptomic_fms

%post
    # Set working directory
    cd /transcriptomic-fms

    # Base container already has PyTorch CUDA, flash-attn, and base package
    # Install scGPT-specific dependencies (skip flash-attn since it's already installed)
    echo "Installing scGPT-specific dependencies..."
    
    # Install package in editable mode first (without extras)
    /root/.local/bin/uv pip install --system \
        --preview-features extra-build-dependencies \
        -e . --no-deps
    
    # Install scgpt dependencies individually (excluding flash-attn which is already installed)
    /root/.local/bin/uv pip install --system \
        --preview-features extra-build-dependencies \
        "scgpt" "gdown" "pyarrow<14.0"

    # Rebuild h5py from source to ensure it links against system HDF5 libraries
    # This is needed because scgpt dependencies might reinstall h5py from a wheel
    echo "Rebuilding h5py to match system HDF5 libraries..."
    /root/.local/bin/uv pip install --system \
        --preview-features extra-build-dependencies \
        --force-reinstall --no-binary h5py h5py || {
        echo "Warning: h5py rebuild failed, but continuing."
    }

    # Ensure torch is still the CUDA version (should already be, but verify)
    /root/.local/bin/uv pip install --system --index-url https://download.pytorch.org/whl/cu121 \
        --upgrade-package torch "torch>=2.0.0,<2.3.0" || true

%environment
    # Inherit all environment from base container (CUDA, HDF5, etc.)
    export PATH="/root/.local/bin:/usr/local/cuda/bin:$PATH"
    export LD_LIBRARY_PATH="/usr/local/cuda/lib64:/usr/lib/x86_64-linux-gnu:/usr/lib:$LD_LIBRARY_PATH"
    export PYTHONPATH="/transcriptomic-fms:$PYTHONPATH"
    export PYTHONUNBUFFERED=1
    export PYTHONNOUSERSITE=1
    export HDF5_DIR=/usr

%runscript
    # Default command
    exec python -m transcriptomic_fms.cli.main "$@"

%labels
    Author "Ahmed Sallam"
    Version "0.1.0"
    Description "Transcriptomic Foundation Models - scGPT container with CUDA support"

