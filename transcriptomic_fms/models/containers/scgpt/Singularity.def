Bootstrap: docker
From: nvidia/cuda:12.1.0-devel-ubuntu22.04

%files
    pyproject.toml /transcriptomic-fms/
    README.md /transcriptomic-fms/
    transcriptomic_fms /transcriptomic-fms/transcriptomic_fms

%post
    # Suppress debconf and update-alternatives warnings
    export DEBIAN_FRONTEND=noninteractive
    export UCF_FORCE_CONFFNEW=1
    
    # Set CUDA and uv paths (set once at the beginning)
    export PATH="/usr/local/cuda/bin:$PATH"
    export LD_LIBRARY_PATH="/usr/local/cuda/lib64:$LD_LIBRARY_PATH"
    
    # Update package lists and install system dependencies
    # Retry apt-get update in case of transient mirror sync issues
    for i in 1 2 3; do
        if apt-get update -qq; then
            break
        else
            if [ $i -eq 3 ]; then
                echo "ERROR: apt-get update failed after 3 attempts"
                exit 1
            fi
            echo "apt-get update failed, retrying in 5 seconds... (attempt $i/3)"
            sleep 5
        fi
    done
    apt-get install -y -qq --no-install-recommends \
        build-essential \
        git \
        curl \
        ca-certificates \
        python3.11 \
        python3.11-dev \
        python3-pip \
        python3-venv \
        libhdf5-dev \
        libhdf5-103 \
        libpng-dev \
        libfreetype6-dev \
        libblas-dev \
        liblapack-dev \
        pkg-config
    
    # Create symlink for python
    ln -sf /usr/bin/python3.11 /usr/bin/python || true
    ln -sf /usr/bin/python3.11 /usr/bin/python3 || true
    
    # Clean up apt lists to reduce image size
    rm -rf /var/lib/apt/lists/*
    
    # Update library cache so system libraries can be found
    ldconfig
    
    # Install uv and add to PATH
    curl -LsSf https://astral.sh/uv/install.sh | sh
    export PATH="/root/.local/bin:$PATH"

    # Set working directory
    cd /transcriptomic-fms

    # Test network connection to PyTorch download servers
    echo "Testing network connection to PyTorch download servers..."
    if curl -s -o /dev/null -w "Connected in %{time_connect}s, total: %{time_total}s\n" \
        --max-time 10 \
        https://download.pytorch.org/whl/cu121/ 2>/dev/null; then
        echo "Network connectivity OK"
    else
        echo "Warning: Connection test failed - network may be slow"
        echo "If PyTorch installation hangs, network speed may be the issue."
    fi

    # Install PyTorch with CUDA support first (before other dependencies)
    echo "Installing PyTorch with CUDA support (downloading wheel, should be fast)..."
    /root/.local/bin/uv pip install --system \
        --preview-features extra-build-dependencies \
        --index-url https://download.pytorch.org/whl/cu121 \
        "torch>=2.0.0,<2.3.0" || {
        echo "ERROR: PyTorch installation failed!"
        exit 1
    }
    echo "PyTorch installed successfully"

    # CRITICAL: Install numpy<2 FIRST and lock it in
    echo "Installing numpy<2 (must be first)..."
    /root/.local/bin/uv pip install --system \
        --preview-features extra-build-dependencies \
        "numpy<2"
    
    # Verify numpy version
    python -c "import numpy; assert int(numpy.__version__.split('.')[0]) < 2, f'ERROR: numpy {numpy.__version__} is >= 2.0'; print(f'numpy {numpy.__version__} installed')" || exit 1
    
    # Now install everything else - pip will find numpy<2 compatible wheels
    echo "Installing scGPT and all dependencies..."
    /root/.local/bin/uv pip install --system \
        --preview-features extra-build-dependencies \
        "scgpt" "torch<=2.2.2" "umap-learn<0.5.7" \
        "wandb" "python-louvain" "gdown" \
        "flash-attn<1.0.5" \
        "ipython" "jupyterlab" "matplotlib" "notebook" "pandas" "python-dotenv" "ruff" "scanpy" "scikit-learn" \
        -e .
    
    # Final check: ensure numpy<2 is still there
    python -c "import numpy; assert int(numpy.__version__.split('.')[0]) < 2, f'ERROR: numpy upgraded to {numpy.__version__}'; print(f'âœ“ numpy {numpy.__version__} confirmed')" || {
        echo "ERROR: numpy was upgraded to 2.x - forcing downgrade..."
        /root/.local/bin/uv pip install --system \
            --preview-features extra-build-dependencies \
            "numpy<2"
    }
    
    # Rebuild h5py from source to ensure it links against the installed HDF5 version
    # h5py wheels may be built against a different HDF5 version than what's in the container
    echo "Rebuilding h5py from source to match system HDF5 libraries..."
    
    # Ubuntu provides libhdf5_serial.so but h5py looks for libhdf5.so
    # Create symlinks so h5py can find the libraries
    cd /lib/x86_64-linux-gnu
    if [ -f "libhdf5_serial.so.103" ] && [ ! -f "libhdf5.so.103" ]; then
        ln -sf libhdf5_serial.so.103 libhdf5.so.103
        ln -sf libhdf5_serial.so libhdf5.so
    fi
    if [ -f "libhdf5_serial_hl.so.100" ] && [ ! -f "libhdf5_hl.so.100" ]; then
        ln -sf libhdf5_serial_hl.so.100 libhdf5_hl.so.100
        ln -sf libhdf5_serial_hl.so libhdf5_hl.so
    fi
    cd /transcriptomic-fms
    
    # Update library cache
    ldconfig
    
    # Set HDF5 environment for h5py build - use ONLY one method (h5py doesn't allow multiple)
    # Option 1: Use HDF5_DIR prefix (simplest)
    # h5py will look in /usr/include and /usr/lib for headers/libs
    # But serial HDF5 is in /usr/include/hdf5/serial, so we need to point there
    # Option 2: Use HDF5_INCLUDEDIR and HDF5_LIBDIR (without HDF5_DIR)
    # Option 3: Use pkg-config (if available)
    
    # Try using just HDF5_DIR first, pointing to where serial HDF5 is
    # But h5py expects standard layout, so let's use include/lib dirs instead
    unset HDF5_DIR || true
    export HDF5_INCLUDEDIR=/usr/include/hdf5/serial
    export HDF5_LIBDIR=/usr/lib/x86_64-linux-gnu
    # Don't set PKG_CONFIG_PATH if we're using include/lib dirs
    
    /root/.local/bin/uv pip install --system \
        --preview-features extra-build-dependencies \
        --force-reinstall --no-binary h5py h5py || {
        echo "ERROR: h5py rebuild failed! This is required for HDF5 compatibility."
        echo "Checking HDF5 installation..."
        ldconfig -p | grep hdf5 || echo "No HDF5 libraries found in cache"
        find /usr/lib -name "*libhdf5*" 2>/dev/null | head -5 || echo "No HDF5 libraries found"
        exit 1
    }
    
    # Verify h5py can import
    echo "Verifying h5py installation..."
    python -c "import h5py; print(f'h5py version: {h5py.__version__}')" || {
        echo "ERROR: h5py import failed after rebuild!"
        exit 1
    }
    
    # Verify numpy version matches scGPT requirements
    echo "Verifying numpy version..."
    python -c "import numpy; print(f'numpy version: {numpy.__version__}')" || echo "WARNING: Could not verify numpy version"

    # Verify torch is still the CUDA version
    /root/.local/bin/uv pip install --system \
        --preview-features extra-build-dependencies \
        --index-url https://download.pytorch.org/whl/cu121 \
        --upgrade-package torch "torch>=2.0.0,<2.3.0" || true

    # Create data and output directories
    mkdir -p /transcriptomic-fms/data
    mkdir -p /transcriptomic-fms/output
    mkdir -p /transcriptomic-fms/models

%environment
    export PATH="/root/.local/bin:/usr/local/cuda/bin:$PATH"
    export LD_LIBRARY_PATH="/usr/local/cuda/lib64:/usr/lib/x86_64-linux-gnu:/usr/lib:$LD_LIBRARY_PATH"
    export PYTHONPATH="/transcriptomic-fms:$PYTHONPATH"
    export PYTHONUNBUFFERED=1
    export PYTHONNOUSERSITE=1
    export HDF5_DIR=/usr

%runscript
    # Default command
    exec python -m transcriptomic_fms.cli.main "$@"

%labels
    Author "Ahmed Sallam"
    Version "0.1.0"
    Description "Transcriptomic Foundation Models - scGPT container with CUDA support"
